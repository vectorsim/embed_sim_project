"""
core_blocks.py
==============

Core base classes for the EmbedSim framework.

Every block natively supports two execution backends, selected at construction:

    use_c_backend=False  (default) — pure Python, no compilation needed
    use_c_backend=True             — compiled Cython wrapper, zero Python
                                     overhead on the hot simulation path

VectorBlock.compute() routes automatically to compute_py() or compute_c().
Subclasses override compute_py() for Python and compute_c() for C.
Never override compute() directly.

Precision:
    All arrays default to float32 (32-bit MCU compatible).
    Per-block:  MyBlock("b", dtype=np.float64)
    Globally:   import embedsim.core_blocks as cb; cb.DEFAULT_DTYPE = np.float64

Author: EmbedSim Framework
Version: 2.0.0
"""

import numpy as np
from typing import List, Optional, Union

# =========================
# Precision Configuration
# =========================

# Change this one line to switch the whole framework to float64.
DEFAULT_DTYPE = np.float32


# =========================
# Signal Representation
# =========================

class VectorSignal:
    """
    A vector-valued signal flowing between EmbedSim blocks.

    Stored as float32 by default (MCU-friendly).

    Attributes:
        value (np.ndarray): Current vector value
        name  (str):        Optional label for plotting / debugging

    Example:
        >>> sig   = VectorSignal([1.0, 2.0], name="current")   # float32
        >>> sig64 = VectorSignal([1.0, 2.0], dtype=np.float64) # float64
    """

    def __init__(self,
                 value: Union[List[float], np.ndarray],
                 name: str = "",
                 dtype=None) -> None:
        _dtype = dtype if dtype is not None else DEFAULT_DTYPE
        self.value: np.ndarray = np.array(value, dtype=_dtype)
        self.name:  str        = name

    def __repr__(self) -> str:
        name_str = f"'{self.name}'" if self.name else "unnamed"
        return (f"VectorSignal({name_str}, shape={self.value.shape}, "
                f"dtype={self.value.dtype}, value={self.value})")


# =========================
# Base Block Class
# =========================

class VectorBlock:
    """
    Abstract base class for every EmbedSim block.

    ── Dual-backend execution ──────────────────────────────────────────────
    Each block supports two modes chosen at construction time:

        use_c_backend=False  (default)
            compute() → compute_py()
            Pure Python, zero setup. Use for development and testing.

        use_c_backend=True
            compute() → compute_c()
            Calls a compiled Cython wrapper with GIL released.
            Use in production. Generate the wrapper once with
            CodeGenEnd.generate_pyx_stub(), compile, then flip the flag.

    ── Implementing a new block ─────────────────────────────────────────────
    • Override compute_py() — required for Python path.
    • Override compute_c()  — optional; needed only if you want C acceleration.
    • Override _load_wrapper() — loads the compiled .pyx wrapper into
                                 self._wrapper (auto-generated by code gen).
    • Do NOT override compute() itself.

    ── Switching backend at runtime ─────────────────────────────────────────
        block.switch_backend(True)   # → C  (wrapper must be loaded first)
        block.switch_backend(False)  # → Python (always safe)

    Attributes:
        name          (str):  Unique block identifier
        use_c_backend (bool): Active backend flag
        dtype:               Numeric dtype for internal arrays (float32 default)
        inputs (List[VectorBlock]): Upstream connected blocks
        output (Optional[VectorSignal]): Latest computed output
        last_output (Optional[VectorSignal]): Previous output (for delays)
        is_dynamic (bool): True if block has integrable internal state

    Example — minimal block with both backends:
        >>> class ScalarGain(VectorBlock):
        ...     def __init__(self, name, gain, **kw):
        ...         super().__init__(name, **kw)
        ...         self.gain = gain
        ...
        ...     def compute_py(self, t, dt, input_values=None):
        ...         y = input_values[0].value * self.gain
        ...         self.output = VectorSignal(y, self.name, dtype=self.dtype)
        ...         return self.output
        ...
        ...     def compute_c(self, t, dt, input_values=None):
        ...         u = np.empty(1, dtype=np.float64)
        ...         u[0] = input_values[0].value[0] if input_values else 0.0
        ...         self._wrapper.set_inputs(u)
        ...         self._wrapper.compute()
        ...         self.output = VectorSignal(self._wrapper.get_outputs(), self.name)
        ...         return self.output
        ...
        ...     def _load_wrapper(self):
        ...         from scalar_gain_wrapper import ScalarGainWrapper
        ...         self._wrapper = ScalarGainWrapper()
        >>>
        >>> g_py = ScalarGain("g", gain=2.0)                      # Python
        >>> g_c  = ScalarGain("g", gain=2.0, use_c_backend=True)  # C
    """

    def __init__(self,
                 name: str = "",
                 use_c_backend: bool = False,
                 dtype=None) -> None:
        self.name:          str                    = name
        self.use_c_backend: bool                   = use_c_backend
        self.dtype                                 = dtype if dtype is not None else DEFAULT_DTYPE
        self.inputs:        List["VectorBlock"]    = []
        self.output:        Optional[VectorSignal] = None
        self.last_output:   Optional[VectorSignal] = None
        self.is_dynamic:    bool                   = False

    # ── Connection ───────────────────────────────────────────────────────────

    def __rshift__(self, other: "VectorBlock") -> "VectorBlock":
        """>> operator: connect this block's output to other's input."""
        other.inputs.append(self)
        return other

    # ── Backend dispatcher (do not override) ─────────────────────────────────

    def compute(self,
                t: float,
                dt: float,
                input_values: Optional[List[VectorSignal]] = None) -> VectorSignal:
        """
        Route to compute_py() or compute_c(). Do NOT override this method.
        """
        if self.use_c_backend:
            return self.compute_c(t, dt, input_values)
        return self.compute_py(t, dt, input_values)

    # ── Python backend ───────────────────────────────────────────────────────

    def compute_py(self,
                   t: float,
                   dt: float,
                   input_values: Optional[List[VectorSignal]] = None) -> VectorSignal:
        """
        Python implementation of this block's transfer function.

        Override in every concrete subclass. Required for pure-Python mode.
        Must assign the result to self.output and return it.

        Raises:
            NotImplementedError: If not overridden.
        """
        raise NotImplementedError(
            f"compute_py() must be implemented by {self.__class__.__name__}"
        )

    # ── C backend ────────────────────────────────────────────────────────────

    def compute_c(self,
                  t: float,
                  dt: float,
                  input_values: Optional[List[VectorSignal]] = None) -> VectorSignal:
        """
        C/Cython implementation of this block's transfer function.

        Override after compiling the wrapper from CodeGenEnd.generate_pyx_stub().

        Typical body:
            u = np.empty(N_IN, dtype=np.float64)
            # ... pack input_values into u ...
            self._wrapper.set_inputs(u)
            self._wrapper.compute()
            y = self._wrapper.get_outputs()
            self.output = VectorSignal(y, self.name)
            return self.output

        Raises:
            NotImplementedError: Until the Cython wrapper is compiled.
        """
        raise NotImplementedError(
            f"{self.name}: compute_c() not implemented. "
            f"Generate the stub with CodeGenEnd.generate_pyx_stub() and compile."
        )

    # ── Wrapper loader ───────────────────────────────────────────────────────

    def _load_wrapper(self) -> None:
        """
        Import the compiled Cython wrapper and store it in self._wrapper.

        Auto-generated by CodeGenEnd.generate_pyx_stub(). Override in the
        generated SimBlock subclass.

        Raises:
            NotImplementedError: Base implementation — always override.
        """
        raise NotImplementedError(
            f"{self.name}: _load_wrapper() not implemented. "
            f"Auto-generated by CodeGenEnd.generate_pyx_stub()."
        )

    # ── State integration (dynamic blocks) ───────────────────────────────────

    def reset(self) -> None:
        """Clear output signals before a new simulation run."""
        self.output      = None
        self.last_output = None

    def get_derivative(self,
                       t: float,
                       input_values: Optional[List[VectorSignal]] = None
                       ) -> Optional[np.ndarray]:
        """Return dx/dt for ODE integration. Override in dynamic blocks."""
        return None

    def integrate_state(self, dt: float, solver: str = 'euler') -> None:
        """Advance internal state by one step. Override in dynamic blocks."""
        pass

    # ── Runtime backend switch ───────────────────────────────────────────────

    def switch_backend(self, use_c: bool) -> None:
        """
        Switch execution backend at runtime.

        Args:
            use_c: True → C backend (wrapper must exist), False → Python

        Raises:
            RuntimeError: If switching to C without a loaded wrapper.
        """
        if use_c and not hasattr(self, '_wrapper'):
            raise RuntimeError(
                f"{self.name}: Cannot switch to C — "
                f"_wrapper not loaded. Call _load_wrapper() first."
            )
        self.use_c_backend = use_c

    def __repr__(self) -> str:
        backend    = "C" if self.use_c_backend else "Python"
        dtype_name = (self.dtype.__name__
                      if hasattr(self.dtype, '__name__') else str(self.dtype))
        return (f"{self.__class__.__name__}"
                f"('{self.name}', backend={backend}, dtype={dtype_name})")


# =========================
# Utility Functions
# =========================

def validate_vector_dimension(signal: VectorSignal,
                               expected_dim: int,
                               block_name: str) -> None:
    """Raise ValueError if signal dimension does not match expected_dim."""
    if len(signal.value) != expected_dim:
        raise ValueError(
            f"{block_name}: Expected signal dimension {expected_dim}, "
            f"but got {len(signal.value)}"
        )


def validate_inputs_exist(input_values: Optional[List[VectorSignal]],
                           block_name: str,
                           min_inputs: int = 1) -> None:
    """Raise ValueError if fewer than min_inputs signals were provided."""
    if not input_values or len(input_values) < min_inputs:
        actual = len(input_values) if input_values else 0
        raise ValueError(
            f"{block_name}: Expected at least {min_inputs} input(s), "
            f"but got {actual}"
        )


# =========================
# Module Metadata
# =========================

__all__ = [
    'DEFAULT_DTYPE',
    'VectorSignal',
    'VectorBlock',
    'validate_vector_dimension',
    'validate_inputs_exist',
]

__version__ = '2.0.0'
__author__  = 'EmbedSim Framework'
